{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Analysing WaPOR data\n",
    "\n",
    "This notebook contains code example to analyse WaPOR data, including:\n",
    "- [1. Calculate the average value of ROI](#1.-Calculate-the-average-value-of-ROI)\n",
    "- [2. Working with timeseries (pandas library)](#2.-Working-with-timeseries-(pandas-library))\n",
    "- [3. Raster calculation](#3.-Raster-calculation)\n",
    "- [4. Land-use analysis](#4.-Land-use-analysis)\n",
    "\n",
    "After the examples, there will be some coding exercises for you to practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and functions\n",
    "For this exercise, we can make use of the user-defined functions we made in the previous exercise to read can write raster data. \n",
    "\n",
    "*First, run the code cell below to import all of them.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gdal\n",
    "import osr\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "import ogr\n",
    "import datetime\n",
    "\n",
    "def GetGeoInfo(fh, subdataset = 0):\n",
    "    \"\"\"\n",
    "    Substract metadata from a geotiff, HDF4 or netCDF file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fh : str\n",
    "        Filehandle to file to be scrutinized.\n",
    "    subdataset : int, optional\n",
    "        Layer to be used in case of HDF4 or netCDF format, default is 0.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    driver : str\n",
    "        Driver of the fh.\n",
    "    NDV : float\n",
    "        No-data-value of the fh.\n",
    "    xsize : int\n",
    "        Amount of pixels in x direction.\n",
    "    ysize : int\n",
    "        Amount of pixels in y direction.\n",
    "    GeoT : list\n",
    "        List with geotransform values.\n",
    "    Projection : str\n",
    "        Projection of fh.\n",
    "    \"\"\"\n",
    "    SourceDS = gdal.Open(fh, gdal.GA_ReadOnly)\n",
    "    Type = SourceDS.GetDriver().ShortName\n",
    "    if Type == 'HDF4' or Type == 'netCDF':\n",
    "        SourceDS = gdal.Open(SourceDS.GetSubDatasets()[subdataset][0])\n",
    "    NDV = SourceDS.GetRasterBand(1).GetNoDataValue()\n",
    "    xsize = SourceDS.RasterXSize\n",
    "    ysize = SourceDS.RasterYSize\n",
    "    GeoT = SourceDS.GetGeoTransform()\n",
    "    Projection = osr.SpatialReference()\n",
    "    Projection.ImportFromWkt(SourceDS.GetProjectionRef())\n",
    "    driver = gdal.GetDriverByName(Type)\n",
    "    return driver, NDV, xsize, ysize, GeoT, Projection\n",
    "\n",
    "def OpenAsArray(fh, bandnumber = 1, dtype = 'float32', nan_values = False):\n",
    "    \"\"\"\n",
    "    Open a map as an numpy array. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fh: str\n",
    "        Filehandle to map to open.\n",
    "    bandnumber : int, optional \n",
    "        Band or layer to open as array, default is 1.\n",
    "    dtype : str, optional\n",
    "        Datatype of output array, default is 'float32'.\n",
    "    nan_values : boolean, optional\n",
    "        Convert he no-data-values into np.nan values, note that dtype needs to\n",
    "        be a float if True. Default is False.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Array : ndarray\n",
    "        Array with the pixel values.\n",
    "    \"\"\"\n",
    "    datatypes = {\"uint8\": np.uint8, \"int8\": np.int8, \"uint16\": np.uint16,\n",
    "                 \"int16\":  np.int16, \"Int16\":  np.int16, \"uint32\": np.uint32,\n",
    "                 \"int32\": np.int32, \"float32\": np.float32, \"float64\": np.float64, \n",
    "                 \"complex64\": np.complex64, \"complex128\": np.complex128,\n",
    "                \"Int32\": np.int32, \"Float32\": np.float32, \"Float64\": np.float64, \n",
    "                 \"Complex64\": np.complex64, \"Complex128\": np.complex128,}\n",
    "    DataSet = gdal.Open(fh, gdal.GA_ReadOnly)\n",
    "    Type = DataSet.GetDriver().ShortName\n",
    "    if Type == 'HDF4':\n",
    "        Subdataset = gdal.Open(DataSet.GetSubDatasets()[bandnumber][0])\n",
    "        NDV = int(Subdataset.GetMetadata()['_FillValue'])\n",
    "    else:\n",
    "        Subdataset = DataSet.GetRasterBand(bandnumber)\n",
    "        NDV = Subdataset.GetNoDataValue()\n",
    "    Array = Subdataset.ReadAsArray().astype(datatypes[dtype])\n",
    "    if nan_values:\n",
    "        Array[Array == NDV] = np.nan\n",
    "    return Array\n",
    "\n",
    "def CreateGeoTiff(fh, Array, driver, NDV, xsize, ysize, GeoT, Projection, explicit = True, compress = None):\n",
    "    \"\"\"\n",
    "    Creates a geotiff from a numpy array.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fh : str\n",
    "        Filehandle for output.\n",
    "    Array: ndarray\n",
    "        Array to convert to geotiff.\n",
    "    driver : str\n",
    "        Driver of the fh.\n",
    "    NDV : float\n",
    "        No-data-value of the fh.\n",
    "    xsize : int\n",
    "        Amount of pixels in x direction.\n",
    "    ysize : int\n",
    "        Amount of pixels in y direction.\n",
    "    GeoT : list\n",
    "        List with geotransform values.\n",
    "    Projection : str\n",
    "        Projection of fh.    \n",
    "    \"\"\"\n",
    "    datatypes = {\"uint8\": 1, \"int8\": 1, \"uint16\": 2, \"int16\": 3, \"Int16\": 3, \"uint32\": 4,\n",
    "    \"int32\": 5, \"float32\": 6, \"float64\": 7, \"complex64\": 10, \"complex128\": 11,\n",
    "    \"Int32\": 5, \"Float32\": 6, \"Float64\": 7, \"Complex64\": 10, \"Complex128\": 11,}\n",
    "    if compress != None:\n",
    "        DataSet = driver.Create(fh,xsize,ysize,1,datatypes[Array.dtype.name], ['COMPRESS={0}'.format(compress)])\n",
    "    else:\n",
    "        DataSet = driver.Create(fh,xsize,ysize,1,datatypes[Array.dtype.name])\n",
    "    if NDV is None:\n",
    "        NDV = -9999\n",
    "    if explicit:\n",
    "        Array[np.isnan(Array)] = NDV\n",
    "    DataSet.GetRasterBand(1).SetNoDataValue(NDV)\n",
    "    DataSet.SetGeoTransform(GeoT)\n",
    "    DataSet.SetProjection(Projection.ExportToWkt())\n",
    "    DataSet.GetRasterBand(1).WriteArray(Array)\n",
    "    DataSet = None\n",
    "    if \"nt\" not in Array.dtype.name:\n",
    "        Array[Array == NDV] = np.nan\n",
    "\n",
    "\n",
    "def MatchProjResNDV(source_file, target_fhs, output_dir, resample = 'near', \n",
    "                    dtype = 'float32', scale = None, ndv_to_zero = False):\n",
    "    \"\"\"\n",
    "    Matches the projection, resolution and no-data-value of a list of target-files\n",
    "    with a source-file and saves the new maps in output_dir.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    source_file : str\n",
    "        The file to match the projection, resolution and ndv with.\n",
    "    target_fhs : list\n",
    "        The files to be reprojected.\n",
    "    output_dir : str\n",
    "        Folder to store the output.\n",
    "    resample : str, optional\n",
    "        Resampling method to use, default is 'near' (nearest neighbour).\n",
    "    dtype : str, optional\n",
    "        Datatype of output, default is 'float32'.\n",
    "    scale : int, optional\n",
    "        Multiple all maps with this value, default is None.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    output_files : ndarray \n",
    "        Filehandles of the created files.\n",
    "    \"\"\"\n",
    "    dst_info=gdal.Info(gdal.Open(source_file),format='json')\n",
    "    output_files = np.array([])\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    for target_file in target_fhs:\n",
    "        folder, fn = os.path.split(target_file)\n",
    "        src_info=gdal.Info(gdal.Open(target_file),format='json')\n",
    "        output_file = os.path.join(output_dir, fn)\n",
    "        gdal.Warp(output_file,target_file,format='GTiff',\n",
    "                      srcSRS=src_info['coordinateSystem']['wkt'],\n",
    "                      dstSRS=dst_info['coordinateSystem']['wkt'],\n",
    "                      srcNodata=src_info['bands'][0]['noDataValue'],\n",
    "                      dstNodata=dst_info['bands'][0]['noDataValue'],\n",
    "                      width=dst_info['size'][0],\n",
    "                      height=dst_info['size'][1],\n",
    "                      outputBounds=(dst_info['cornerCoordinates']['lowerLeft'][0],\n",
    "                                    dst_info['cornerCoordinates']['lowerLeft'][1],\n",
    "                                    dst_info['cornerCoordinates']['upperRight'][0],\n",
    "                                    dst_info['cornerCoordinates']['upperRight'][1]),\n",
    "                      outputBoundsSRS=dst_info['coordinateSystem']['wkt'],\n",
    "                      resampleAlg=resample)\n",
    "        output_files = np.append(output_files, output_file)\n",
    "        if not np.any([scale == 1.0, scale == None, scale == 1]):\n",
    "            driver, NDV, xsize, ysize, GeoT, Projection = GetGeoInfo(output_file)\n",
    "            DATA = OpenAsArray(output_file, nan_values = True) * scale\n",
    "            CreateGeoTiff(output_file, DATA, driver, NDV, xsize, ysize, GeoT, Projection)\n",
    "        if ndv_to_zero:\n",
    "            driver, NDV, xsize, ysize, GeoT, Projection = GetGeoInfo(output_file)\n",
    "            DATA = OpenAsArray(output_file, nan_values = False)\n",
    "            DATA[DATA == NDV] = 0.0\n",
    "            CreateGeoTiff(output_file, DATA, driver, NDV, xsize, ysize, GeoT, Projection)\n",
    "    return output_files\n",
    "\n",
    "def CliptoShp(input_fhs,output_folder,shp_fh,NDV=-9999):\n",
    "    \"\"\"\n",
    "    Clip raster to boundary line of a shapefile\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_fhs : list\n",
    "        The list of input raster files\n",
    "    output_folder : str\n",
    "        The path to folder where to save output rasters\n",
    "    shp_fh : str\n",
    "        Folder to store the output.\n",
    "    NDV : float or int, optional\n",
    "        No Data Value of output raster\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    output_fhs : list \n",
    "        Filehandles of the created files.\n",
    "    \"\"\"\n",
    "    inDriver = ogr.GetDriverByName(\"ESRI Shapefile\")\n",
    "    inDataSource = inDriver.Open(shp_fh, 1)\n",
    "    inLayer = inDataSource.GetLayer()    \n",
    "    options = gdal.WarpOptions(cutlineDSName = shp_fh,\n",
    "                               cutlineLayer = inLayer.GetName(),\n",
    "                               cropToCutline = True, \n",
    "                               dstNodata=NDV\n",
    "                               )\n",
    "    output_fhs=[]\n",
    "    for input_fh in input_fhs:\n",
    "        output_fh=os.path.join(output_folder,os.path.basename(input_fh))\n",
    "        sourceds = gdal.Warp(output_fh, input_fh, options = options)\n",
    "        output_fhs.append(output_fh)\n",
    "    return output_fhs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Calculate the average value of ROI\n",
    "### Example\n",
    "Calculate average precipitation in a Region of Interest (ROI) from a raster map (mm/month). \n",
    "\n",
    "\n",
    "*ET_folder* and *P_folder* are the paths to the Actual Evapotranspiration and Interception and Precipitation folder downloaded from the exercise in the notebook [3 Bulk download WaPOR data](3_Bulk_download_WaPOR_data.ipynb). If the files are downloaded succesfully, the number of files in the two folders will be 24 each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in .\\data\\WAPOR.v2_monthly_L1_PCP_M: 24\n",
      "Number of files in .\\data\\WAPOR.v2_monthly_L1_AETI_M: 0\n"
     ]
    }
   ],
   "source": [
    "# Define ET and P folder:\n",
    "ET_folder=r\".\\data\\WAPOR.v2_monthly_L1_AETI_M\"\n",
    "P_folder=r\".\\data\\WAPOR.v2_monthly_L1_PCP_M\"\n",
    "# Get list of files in folder:\n",
    "P_fhs=sorted(glob.glob(os.path.join(P_folder,'*.tif')))\n",
    "ET_fhs=sorted(glob.glob(os.path.join(ET_folder,'*.tif')))\n",
    "print('Number of files in {0}: {1}'.format(P_folder,len(P_fhs)))\n",
    "print('Number of files in {0}: {1}'.format(ET_folder,len(ET_fhs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, check if the Precipitation map is warped to the same size with the AETI map of ROI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-b7ccdd6296ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Get the path of the first file:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mP_fh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mP_fhs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mET_fh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mET_fhs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# Open the files as array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mP\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mOpenAsArray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mP_fh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnan_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Get the path of the first file:\n",
    "P_fh=P_fhs[0]\n",
    "ET_fh=ET_fhs[0]\n",
    "# Open the files as array\n",
    "P=OpenAsArray(P_fh,nan_values=True)\n",
    "ET=OpenAsArray(ET_fh,nan_values=True)\n",
    "#print shape of arrays\n",
    "print(P.shape)\n",
    "print(ET.shape)\n",
    "\n",
    "plt.imshow(P)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of ET and P arrays are different because resolution of Level 1 Precipitation is 5km and that of ET is 250m. To warp all the precipitation rasters to the same resolution with Land cover classification raster, use the defined function *MatchProjResNDV*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we can get the average Precipitation of the whole area by *numpy.nanmean* which means calculate the average excluding pixels with nan values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P=OpenAsArray(P_fhs[0],nan_values=True)\n",
    "plt.imshow(P)\n",
    "plt.show()\n",
    "Average_P=np.nanmean(P)\n",
    "print('Average Precipitation (mm/month): {0}'.format(Average_P))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get values of all monthly Precipitation (P) maps and save the value in a Python *list* and plot average precipitation against time, we will loop over all the monthly P rasters and calculate average P and the date.\n",
    "\n",
    "We can make use of the file name to get *datetime* index. Look at example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dates=[] \n",
    "months=[]\n",
    "years=[]\n",
    "P_values=[]\n",
    "for P_fh in P_fhs:\n",
    "    filename=os.path.basename(P_fh) # get file name from filehandler string\n",
    "    datestr=filename.split('.')[0].split('_')[-1] #get date string from file name\n",
    "    dyear=int('20'+datestr[0:2]) #get year number from date string\n",
    "    dmonth=int(datestr[2:4]) #get month number from date string\n",
    "    dates.append(datetime.date(dyear,dmonth,1)) # create datetime object from year and month number\n",
    "    months.append(dmonth) #append to months list\n",
    "    years.append(dyear) # append to years list\n",
    "    #Calculate value\n",
    "    P=OpenAsArray(P_fh,nan_values=True) #open raster as numpy array    \n",
    "    Average_P=np.nanmean(P) # calculate average P\n",
    "    P_values.append(Average_P)    #append to P_values list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After extract monthly average value of the rasters, we can plot the **P_values** to see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(P_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can decorate our graph with some extra code. For example, run the code below and see the output graph. You can try to customize the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir=r'.\\data'\n",
    "fig = plt.figure(figsize = (10,5))\n",
    "plt.clf() #clear plot\n",
    "plt.grid(b=True, which='Major', color='0.65',linestyle='--', zorder = 0) # Add Grid line\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(dates, P_values, '-k') #Plot data as black line\n",
    "ax.fill_between(dates, P_values, color = '#6bb8cc') #Fill line area with blue color\n",
    "ax.set_xlabel('Time') #Add X axis title\n",
    "ax.set_ylabel('Precipitation [mm/month]') #Add Y axis title\n",
    "ax.set_title('Precipitation, Awash Basin') #Add Figure title\n",
    "fig.autofmt_xdate() #auto-format dates axis\n",
    "plt.savefig(os.path.join(output_dir, 'Precipitation_Awash_ts.png')) #save figure to output\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Working with timeseries (pandas library)\n",
    "### Example\n",
    "The lists created (*dates*, *months*, *years*, *P_values*) can be combined in a DataFrame object using *pandas.DataFrame*. This structure makes cleaning, transforming, manipulating and analyzing data easier. For example, the code below create a DataFrame from the list of dates and average Precipitation values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "P_df=pd.DataFrame({'date':dates,'month':months,'year':years,'value': P_values})\n",
    "P_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can easily sum up precipitation of the monthly values into the yearly total precipitation using *groupby* of column *year* with method *sum*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Year_total=P_df.groupby(['year']).sum()\n",
    "Year_total['value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataFrame columns can be converted to array and plotted easily. Below is the code to plot the total yearly precipitation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,5))\n",
    "ax2 = plt.subplot(111)\n",
    "ax2.grid(b=True, which='Major', color='0.65',linestyle='--', zorder = 0) #Grid line\n",
    "ax2.bar(Year_total.index, Year_total['value'].values, 0.8, color = '#6bb8cc')\n",
    "ax2.set_xlabel('Time [Year]')\n",
    "ax2.set_xticks(Year_total.index)\n",
    "ax2.set_ylabel('Precipitation [mm/year]')\n",
    "ax2.set_title('Yearly Total Precipitation, Awash')\n",
    "plt.savefig(os.path.join(output_dir, 'Precipitation_Awash_year.png'))\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate and plot the mean Precipitation of the calendar months, we can *groupby* method, and use *mean* instead of *sum*: **P_df.groupby(['month']).mean()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Month_avg=P_df.groupby(['month']).mean()\n",
    "Month_avg['value']\n",
    "fig = plt.figure(figsize = (10,5))\n",
    "#subplot 1\n",
    "ax1 = plt.subplot(111)\n",
    "ax1.grid(b=True, which='Major', color='0.65',linestyle='--', zorder = 0) #Grid line\n",
    "ax1.bar(Month_avg.index, Month_avg['value'].values, 0.8, color = '#6bb8cc')\n",
    "ax1.set_xlabel('Time [month]')\n",
    "monthname={1:'Jan',2:'Feb',3:'Mar',4:'Apr',5:'May',6:'Jun',7:'Jul',8:'Aug',9:'Sep',10:'Oct',11:'Nov',12:'Dec'}\n",
    "monthslabel=monthname.values()\n",
    "ax1.set_xticks(Month_avg.index)\n",
    "ax1.set_xticklabels(monthslabel)\n",
    "ax1.set_ylabel('Precipitation [mm/month]')\n",
    "ax1.set_title('Monthly average Precipitation, Awash')\n",
    "plt.savefig(os.path.join(output_dir, 'Precipitation_Awash_month.png'))\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also save our dataframe as csv file using pandas.DataFrame method *to_csv* for later use in other analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Month_max=P_df.groupby(['month']).max()\n",
    "Month_min=P_df.groupby(['month']).min()\n",
    "Month_med=P_df.groupby(['month']).median()\n",
    "Month_std=P_df.groupby(['month']).std()\n",
    "\n",
    "Month_stat=pd.DataFrame({'month': Month_avg.index,'Mean':Month_avg['value'].values,\n",
    "                        'Max':Month_max['value'].values, 'Min':Month_min['value'].values,\n",
    "                        'Median':Month_med['value'].values,'Std':Month_std['value'].values})\n",
    "print(Month_stat)\n",
    "Month_stat.to_csv(r'.\\data\\P_month_stats.csv',sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Raster calculation\n",
    "### Example: P - ET\n",
    "First, we need to get the file handler of the P and ET rasters of the same date that have been matched projection, size and resolution. We can make use of the time format in file name as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_date='2009-01-01'\n",
    "end_date='2010-12-31'\n",
    "dates=pd.date_range(start_date,end_date,freq='M') #create a date range from start_date and end_date\n",
    "\n",
    "P_path=r'.\\data\\WAPOR.v2_monthly_L1_PCP_M_clipped\\L1_PCP_{:2}{:02d}M.tif' #template string to format\n",
    "ET_path=r'.\\data\\WAPOR.v2_monthly_L1_AETI_M_clipped\\L1_AETI_{:2}{:02d}M.tif' #template string to format\n",
    "\n",
    "date=dates[0] #get the first date in the date range\n",
    "print(date)\n",
    "P_fh=P_path.format(str(date.year)[2:],date.month) #format filename using the selected date\n",
    "ET_fh=ET_path.format(str(date.year)[2:],date.month) #format filename using the selected date\n",
    "print(P_fh)\n",
    "print(ET_fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between Precipitation and Total EvapoTranspiration (P-ET) of the pixel can indicate whether the pixel is sink or source of water. When P-ET>0, water is generated in the pixel area. When P-ET< 0, water is more depleted in the pixel area. For example, below is how we can calculate P-ET for one month (January 2009). Notice where P-ET is negative and positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P=OpenAsArray(P_fh,nan_values=True)\n",
    "ET=OpenAsArray(ET_fh,nan_values=True)\n",
    "P_ET=P-ET\n",
    "plt.imshow(P_ET)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a for-loop to calculate P-ET maps for the month in 2009. The output files will be save in the folder [P-ET_M](data/P-ET_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_folder=r'.\\data\\P-ET_M'\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "for date in dates:\n",
    "    print(date)\n",
    "    P_fh=P_path.format(str(date.year)[2:],date.month) #format filename using the selected date\n",
    "    ET_fh=ET_path.format(str(date.year)[2:],date.month) #format filename using the selected date \n",
    "    driver, NDV, xsize, ysize, GeoT, Projection=GetGeoInfo(P_fh)\n",
    "    P=OpenAsArray(P_fh,nan_values=True)\n",
    "    ET=OpenAsArray(ET_fh,nan_values=True)\n",
    "    P_ET=P-ET\n",
    "    filename='P-ET_{:2}{:02d}M.tif'.format(str(date.year)[2:],date.month)\n",
    "    output_fh=os.path.join(output_folder,filename)\n",
    "    print(output_fh)\n",
    "    CreateGeoTiff(output_fh, P_ET, driver, NDV, xsize, ysize, GeoT, Projection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "Follow the example of how monthly average Precipitation was calculated in the examples, calculate and plot monthly P - ET of the year 2009 and 2010 in Awash Basin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Write your code here'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Land-use analysis\n",
    "### Example:\n",
    "We will first clip the WaPOR LCC rasters downloaded from [3 Bulk download WaPOR data](3_Bulk_download_WaPOR_data.ipynb) then get the list of unique Land Cover classes from WaPOR Land Cover Classification rasters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_fh=r\".\\data\\Awash_shapefile.shp\"\n",
    "LCC_folder=r'.\\data\\WAPOR.v2_yearly_L1_LCC_A'\n",
    "LCC_fhs=sorted(glob.glob(os.path.join(LCC_folder,'*.tif'))) #get list of LCC rasters\n",
    "output_folder=r'.\\data\\WAPOR.v2_yearly_L1_LCC_A_clipped' # New LCC folder\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder) #create new P folder\n",
    "LCC_fhs=CliptoShp(LCC_fhs,output_folder,shp_fh) #clip all LCC rasters to shapefile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will open 1 LCC map as numpy array to get the unique values in map. These are the Land Cover Classification codes. For the description of these LCC codes, see the Land Cover Classification metadata on WaPOR catalog https://wapor.apps.fao.org/catalog/WAPOR_2/1/L1_LCC_A\n",
    "\n",
    "| code        | Name          | \n",
    "| :---------: |:-------------:| \n",
    "| 20 | Shrubland      | \n",
    "| 30      |  Grassland      | \n",
    "| 41      | Cropland, rainfed      | \n",
    "| 42      | Cropland, irrigated or under water management  |\n",
    "| 43      | Cropland, fallow |   \n",
    "| 50 | Built-up      |  \n",
    "| 60 | Bare / sparse vegetation       | \n",
    "| 80 | Water bodies       | \n",
    "| 112 | Tree cover: closed, evergreen broadleaved      | \n",
    "| 114 |  Tree cover: closed, deciduous broadleaved | \n",
    "| 116 | Tree cover: closed, unknown type | \n",
    "| 124 | Tree cover: open, deciduous broadleaved | \n",
    "| 126 |  Tree cover: open, unknown type  | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LCC_fh=r\".\\data\\WAPOR.v2_yearly_L1_LCC_A_clipped\\L1_LCC_09.tif\"\n",
    "LCC=OpenAsArray(LCC_fh,nan_values=True)\n",
    "LCC_values=np.unique(LCC[~np.isnan(LCC)])\n",
    "LCC_codes=list(LCC_values)\n",
    "print(LCC_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate average ET of each land cover, we can mask the ET map where the LCC map values equal to each LCC code, then calculate **np.nanmean** of the masked array.\n",
    "For example, to get ET value of water bodies (the LCC code is 80), we can use the steps below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code=80 #Water bodies\n",
    "\n",
    "mask=np.where(LCC==code,0,1)\n",
    "in_fh=r\".\\data\\WAPOR.v2_monthly_L1_AETI_M_clipped\\L1_AETI_0901M.tif\"\n",
    "var=OpenAsArray(in_fh,nan_values=True)\n",
    "\n",
    "import numpy.ma as ma #import mask array module\n",
    "masked_map=ma.masked_array(var,mask)\n",
    "plt.imshow(masked_map)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we can calculate average ET of a the water bodies land-use class using the masked array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average=np.nanmean(masked_map)\n",
    "print('Landuse class {0} Average: {1}'.format(code,average))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use a for-loop over the unique LCC codes to calculate average ET value of each LCC code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "averages=[]\n",
    "for code in LCC_codes:\n",
    "    mask=np.where(LCC==code,0,1)\n",
    "    masked_map=ma.masked_array(var,mask)\n",
    "    averages.append(np.nanmean(masked_map))\n",
    "LCC_avg=pd.DataFrame({'LCC code':LCC_codes,'Average Value': averages})\n",
    "LCC_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2:\n",
    "\n",
    "Calculate a table of average annual P-ET in Awash basin of all land-use class for the year 2009. \n",
    "\n",
    "**Hints**: The first step is to sum all the monthly P-ET rasters in the year 2009 to calculate annual P - ET of that year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date='2009-01-01'\n",
    "end_date='2009-12-31'\n",
    "dates=pd.date_range(start_date,end_date,freq='M') #create a date range from start_date and end_date\n",
    "PmET_path=r'.\\data\\P-ET_M\\P-ET_{:2}{:02d}M.tif'\n",
    "sameple_file=PmET_path.format(str(dates[0].year)[2:],dates[0].month)\n",
    "driver, NDV, xsize, ysize, GeoT, Projection=GetGeoInfo(sameple_file)\n",
    "SumArray=np.zeros((ysize,xsize))\n",
    "for date in dates:\n",
    "    print(date)\n",
    "    PmET_fh=PmET_path.format(str(date.year)[2:],date.month) #format filename using the selected date\n",
    "    SumArray+=OpenAsArray(PmET_fh,nan_values=True)\n",
    "output_fh=os.path.join('.\\data\\P-ET_2009.tif')\n",
    "CreateGeoTiff(output_fh, P_ET, driver, NDV, xsize, ysize, GeoT, Projection)\n",
    "plt.imshow(SumArray)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, using the similar steps that were used to calculate average ET of each land cover class to calculate P -ET per land cover class.\n",
    "\n",
    "Compare Evaporation in the main classes: Forest, Shrubland, Grassland, Water bodies, Bare land, Rainfed crops, Irrigated crops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Write your code here'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
